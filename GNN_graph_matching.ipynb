{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GNN_graph_matching.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "DcQsqc_0AQra",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Initialization"
      ]
    },
    {
      "metadata": {
        "id": "G30iqwTmhgal",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uyaXrUEwVbqi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import networkx\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j2C6EYvy8iXG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "dtype = torch.cuda.FloatTensor\n",
        "dtype_l = torch.cuda.LongTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bIplHBdirPXS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data generator"
      ]
    },
    {
      "metadata": {
        "id": "4VAxrmBfVbqO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1250
        },
        "outputId": "754a2939-ed3f-4bac-9a59-a72576c695b0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525719620044,
          "user_tz": 240,
          "elapsed": 1282,
          "user": {
            "displayName": "Luca Venturi",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "101973500851832681079"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class dataGenerator:\n",
        "    def __init__(self):\n",
        "        self.NUM_SAMPLES_train = int(10e6)\n",
        "        self.NUM_SAMPLES_test = int(10e4)\n",
        "        self.data_train = []\n",
        "        self.data_test = []\n",
        "        self.J = 3\n",
        "        self.N = 50\n",
        "        self.edge_density = 0.2\n",
        "        self.noise = 0.03\n",
        "        \n",
        "    def ErdosRenyi(self, p, N):\n",
        "        G = networkx.erdos_renyi_graph(N, p)\n",
        "        W = networkx.adjacency_matrix(G).todense().astype(float)\n",
        "        W = np.array(W)\n",
        "        return W\n",
        "      \n",
        "    def compute_operators(self, W):\n",
        "        N = W.shape[0]\n",
        "        # OP = operators: {Id, W, W^2, ..., W^{J-1}, D, U}\n",
        "        deg = W.sum(1)\n",
        "        D = np.diag(deg)\n",
        "        W_pow = W.copy()\n",
        "        OP = np.zeros([N, N, self.J + 2])\n",
        "        OP[:, :, 0] = np.eye(N)\n",
        "        for j in range(self.J):\n",
        "            OP[:, :, j + 1] = W_pow.copy()\n",
        "            W_pow = np.minimum(np.dot(W_pow, W_pow), np.ones(W_pow.shape))\n",
        "        OP[:, :, self.J] = D\n",
        "        OP[:, :, self.J + 1] = np.ones((N, N)) * (1.0 / float(N))\n",
        "        x = np.reshape(deg, (N, 1))\n",
        "        return OP, x\n",
        "        \n",
        "    def compute_sample(self):\n",
        "        sample = {}\n",
        "        W = self.ErdosRenyi(self.edge_density,self.N)\n",
        "        # noise model from [arxiv 1602.04181], eq. (3.10)\n",
        "        pe1 = self.noise\n",
        "        pe2 = (self.edge_density * self.noise) / (1.0 - self.edge_density)\n",
        "        noise1 = self.ErdosRenyi(pe1, self.N)\n",
        "        noise2 = self.ErdosRenyi(pe2, self.N)\n",
        "        noisey_W = W * (1 - noise1) + (1 - W) * noise2\n",
        "        sample['OP'], sample['x'] = self.compute_operators(W)\n",
        "        sample['noisey_OP'], sample['noisey_x'] = self.compute_operators(noisey_W)\n",
        "        return sample\n",
        "    \n",
        "    def create_train_dataset(self):\n",
        "        self.data_train = []\n",
        "        for _ in range(self.NUM_SAMPLES_train):\n",
        "            sample = self.compute_sample()\n",
        "            self.data_train.append(sample)\n",
        "            \n",
        "    def create_test_dataset(self):\n",
        "        self.data_test = []\n",
        "        for _ in range(self.NUM_SAMPLES_test):\n",
        "            sample = self.compute_sample()\n",
        "            self.data_test.append(sample)\n",
        "            \n",
        "    def sample_batch(self, BATCH_SIZE, is_training=True, cuda=True, volatile=False):\n",
        "        if is_training:\n",
        "            data = self.data_train\n",
        "        else:\n",
        "            data = self.data_test\n",
        "        OP_size = data[0]['OP'].shape\n",
        "        x_size = data[0]['x'].shape\n",
        "        \n",
        "        OP = torch.zeros(OP_size).expand(BATCH_SIZE, *OP_size)\n",
        "        x = torch.zeros(x_size).expand(BATCH_SIZE, *x_size)\n",
        "        noisey_OP = torch.zeros(OP_size).expand(BATCH_SIZE, *OP_size)\n",
        "        noisey_x = torch.zeros(x_size).expand(BATCH_SIZE, *x_size)\n",
        "        \n",
        "        for i in range(BATCH_SIZE):\n",
        "            if is_training:\n",
        "                ind = np.random.randint(0, len(data))\n",
        "            else:\n",
        "                ind = i\n",
        "            OP[i] = torch.from_numpy(data[ind]['OP'])\n",
        "            x[i] = torch.from_numpy(data[ind]['x'])\n",
        "            noisey_OP[i] = torch.from_numpy(data[ind]['noisey_OP'])\n",
        "            noisey_x[i] = torch.from_numpy(data[ind]['noisey_x'])\n",
        "            \n",
        "        OP = Variable(OP, volatile=volatile)\n",
        "        x = Variable(x, volatile=volatile)\n",
        "        noisey_OP = Variable(noisey_OP, volatile=volatile)\n",
        "        noisey_x = Variable(noisey_x, volatile=volatile)\n",
        "        \n",
        "        if cuda:\n",
        "            return [OP.cuda(), x.cuda()], [noisey_OP.cuda(), noisey_x.cuda()]\n",
        "        else:\n",
        "            return [OP, x], [noisey_OP, noisey_x]\n",
        "          \n",
        "# Test\n",
        "\n",
        "generator = dataGenerator()\n",
        "generator.NUM_SAMPLES_train = 100\n",
        "generator.NUM_SAMPLES_test = 100\n",
        "generator.N = 50\n",
        "J = 5\n",
        "generator.J = J-2\n",
        "generator.create_train_dataset()\n",
        "generator.create_test_dataset()\n",
        "G1, G2 = generator.sample_batch(32)\n",
        "print(G1[0].size())\n",
        "print(G1[1][0].data.cpu().numpy())\n",
        "G1 = G1[0][0, :, :, 1]\n",
        "G2 = G2[0][0, :, :, 1]\n",
        "print(G1, G1.size())\n",
        "print(G2, G2.size())\n",
        "\n",
        "# Test: OK"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 50, 50, 5])\n",
            "[[ 8.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [ 7.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [11.]\n",
            " [10.]\n",
            " [12.]\n",
            " [ 6.]\n",
            " [ 7.]\n",
            " [ 9.]\n",
            " [ 8.]\n",
            " [ 6.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [ 7.]\n",
            " [12.]\n",
            " [ 6.]\n",
            " [11.]\n",
            " [ 6.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [10.]\n",
            " [ 7.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [ 7.]\n",
            " [13.]\n",
            " [10.]\n",
            " [11.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [ 6.]\n",
            " [10.]\n",
            " [ 7.]\n",
            " [ 8.]\n",
            " [12.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [ 6.]\n",
            " [ 7.]\n",
            " [11.]\n",
            " [ 5.]\n",
            " [ 8.]\n",
            " [12.]]\n",
            "Variable containing:\n",
            "    0     0     0  ...      0     0     0\n",
            "    0     0     0  ...      0     0     0\n",
            "    0     0     0  ...      1     0     0\n",
            "       ...          ⋱          ...       \n",
            "    0     0     1  ...      0     0     1\n",
            "    0     0     0  ...      0     0     0\n",
            "    0     0     0  ...      1     0     0\n",
            "[torch.cuda.FloatTensor of size 50x50 (GPU 0)]\n",
            " torch.Size([50, 50])\n",
            "Variable containing:\n",
            "    0     0     0  ...      0     0     0\n",
            "    0     0     0  ...      0     0     0\n",
            "    0     0     0  ...      1     0     0\n",
            "       ...          ⋱          ...       \n",
            "    0     0     1  ...      0     0     0\n",
            "    0     0     0  ...      0     0     0\n",
            "    0     0     0  ...      0     0     0\n",
            "[torch.cuda.FloatTensor of size 50x50 (GPU 0)]\n",
            " torch.Size([50, 50])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fvh2FOMygjVq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GNN Model"
      ]
    },
    {
      "metadata": {
        "id": "T7OrzwsVOzgA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf65c7a3-1a39-4d33-fce7-4087cf299c3d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525719928062,
          "user_tz": 240,
          "elapsed": 1590,
          "user": {
            "displayName": "Luca Venturi",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "101973500851832681079"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def gmul(input):\n",
        "    W, x = input\n",
        "    # x is a tensor of size (bs, N, num_features)\n",
        "    # W is a tensor of size (bs, N, N, J)\n",
        "    N = W.size()[-2]\n",
        "    W = W.split(1, 3) # W is a list of J tensors of size (bs, N, N, 1)\n",
        "    W = torch.cat(W, 1).squeeze(3) # W is now a tensor of size (bs, J*N, N)\n",
        "    output = torch.bmm(W, x) # matrix multiplication (J*N,N) x (N,num_features): output has size (bs, J*N, num_features)\n",
        "    output = output.split(N, 1) # output is a list of J tensors of size (bs, N, num_features)\n",
        "    output = torch.cat(output, 2)\n",
        "    # output has size (bs, N, J*num_features)\n",
        "    return output\n",
        "\n",
        "class Gconv(nn.Module):\n",
        "    def __init__(self, feature_maps, J):\n",
        "        super(Gconv, self).__init__()\n",
        "        self.num_inputs = J*feature_maps[0] # size of the input\n",
        "        self.num_outputs = feature_maps[1] # size of the output\n",
        "        self.fc1 = nn.Linear(self.num_inputs, self.num_outputs // 2)\n",
        "        self.fc2 = nn.Linear(self.num_inputs, self.num_outputs // 2)\n",
        "        self.bn = nn.BatchNorm1d(self.num_outputs)\n",
        "\n",
        "    def forward(self, input):\n",
        "        W = input[0]\n",
        "        x = gmul(input) # x has size (bs, N, num_inputs)\n",
        "        x_size = x.size()\n",
        "        x = x.contiguous() # makes sure that x is stored in a contiguous chunk of memory\n",
        "        x = x.view(-1, self.num_inputs)\n",
        "        x1 = F.relu(self.fc1(x)) # x_1 has size (bs*N, num_outputs // 2)\n",
        "        x2 = self.fc2(x) # x_2 has size (bs*N, num_outputs // 2)\n",
        "        x = torch.cat((x1, x2), 1) # x has size (bs*N, num_outputs)\n",
        "        x = self.bn(x)\n",
        "        x = x.view(*x_size[:-1], self.num_outputs) # x has size (bs, N, num_outputs)\n",
        "        return W, x\n",
        "      \n",
        "class Gconv_last(nn.Module):\n",
        "    def __init__(self, feature_maps, J):\n",
        "        super(Gconv_last, self).__init__()\n",
        "        self.num_inputs = J*feature_maps[0] # size of the input\n",
        "        self.num_outputs = feature_maps[1] # size of the output\n",
        "        self.fc = nn.Linear(self.num_inputs, self.num_outputs) # the only difference is that there is no activations layer\n",
        "\n",
        "    def forward(self, input):\n",
        "        W = input[0]\n",
        "        x = gmul(input) # out has size (bs, N, num_inputs)\n",
        "        x_size = x.size()\n",
        "        x = x.contiguous()\n",
        "        x = x.view(x_size[0]*x_size[1], -1) # x has size (bs*N, num_inputs)\n",
        "        x = self.fc(x) # x has size (bs*N, num_outputs)\n",
        "        x = x.view(*x_size[:-1], self.num_outputs) # x has size (bs, N, num_outputs)\n",
        "        return W, x\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, num_features, num_layers, J):\n",
        "        super(GNN, self).__init__()\n",
        "        self.num_features = num_features\n",
        "        self.num_layers = num_layers\n",
        "        self.featuremap_first = [1, num_features]\n",
        "        self.featuremap = [num_features, num_features]\n",
        "        self.layer0 = Gconv(self.featuremap_first, J)\n",
        "        for i in range(num_layers):\n",
        "            module = Gconv(self.featuremap, J)\n",
        "            self.add_module('layer{}'.format(i + 1), module)\n",
        "        self.layerlast = Gconv_last(self.featuremap, J)\n",
        "\n",
        "    def forward(self, input):\n",
        "        cur = self.layer0(input)\n",
        "        for i in range(self.num_layers):\n",
        "            cur = self._modules['layer{}'.format(i+1)](cur)\n",
        "        out = self.layerlast(cur)\n",
        "        return out[1]\n",
        "      \n",
        "class Siamese_GNN(nn.Module):\n",
        "    def __init__(self, num_features, num_layers, J):\n",
        "        super(Siamese_GNN, self).__init__()\n",
        "        self.gnn = GNN(num_features, num_layers, J)\n",
        "        \n",
        "    def forward(self, G1, G2):\n",
        "        emb1 = self.gnn(G1)\n",
        "        emb2 = self.gnn(G2)\n",
        "        # emb_ is a tensor of size (bs, N, num_features)\n",
        "        out = torch.bmm(emb1, emb2.permute(0, 2, 1))\n",
        "        # out is a tensor of size (bs, N, N)\n",
        "        return out\n",
        "      \n",
        "# Test\n",
        "\n",
        "num_features = 10\n",
        "num_layers = 5\n",
        "siamese_gnn = Siamese_GNN(num_features, num_layers, J).type(dtype)\n",
        "G1, G2 = generator.sample_batch(32)\n",
        "out = siamese_gnn(G1, G2)\n",
        "print(out.size())\n",
        "\n",
        "# Test: OK"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 50, 50])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I4-8O1m49VhA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loss function"
      ]
    },
    {
      "metadata": {
        "id": "ht3hYCa7Ozgc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "base_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "def compute_loss(pred, labels):\n",
        "    # pred has size (bs, N, N)\n",
        "    # labels has size (bs,N)\n",
        "    pred = pred.view(-1, pred.size()[-1])\n",
        "    labels = labels.view(-1)\n",
        "    return base_loss(pred, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m7pLn2lqBx-6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Optimizer"
      ]
    },
    {
      "metadata": {
        "id": "Xr2XtjK3B3gw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def get_optimizer(model):\n",
        "    optimizer = optim.Adam(model.type(dtype).parameters(), lr=1e-3)\n",
        "    return optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UMBxKhQAS36A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Logger"
      ]
    },
    {
      "metadata": {
        "id": "Rwt2nQxbL7PE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def compute_recovery_rate(pred, labels):\n",
        "    pred = pred.argmax(2)\n",
        "    error = 1 - torch.eq(pred, labels).type(dtype)\n",
        "    frob_norm = error.mean(1)\n",
        "    accuracy = 1 - frob_norm\n",
        "    accuracy = accuracy.mean(0).squeeze()\n",
        "    return accuracy.data.cpu().numpy()[0]\n",
        "\n",
        "class make_logger(object):\n",
        "    def __init__(self):\n",
        "        self.loss_train = []\n",
        "        self.loss_test = []\n",
        "        self.accuracy_train = []\n",
        "        self.accuracy_test = []\n",
        "        self.args = {}\n",
        "\n",
        "    def add_train_loss(self, loss):\n",
        "        self.loss_train.append(loss.data.cpu().numpy())\n",
        "\n",
        "    def add_test_loss(self, loss):\n",
        "        self.loss_test.append(loss)\n",
        "\n",
        "    def add_train_accuracy(self, pred, labels):\n",
        "        accuracy = compute_recovery_rate(pred, labels)\n",
        "        self.accuracy_train.append(accuracy)\n",
        "\n",
        "    def add_test_accuracy(self, pred, labels):\n",
        "        accuracy = compute_recovery_rate(pred, labels)\n",
        "        self.accuracy_test.append(accuracy)\n",
        "\n",
        "    def plot_train_loss(self):\n",
        "        plt.figure(0)\n",
        "        plt.clf()\n",
        "        iters = range(len(self.loss_train))\n",
        "        plt.semilogy(iters, self.loss_train, 'b')\n",
        "        plt.xlabel('iterations')\n",
        "        plt.ylabel('Cross Entropy Loss')\n",
        "        plt.title('Training Loss: p={}, p_e={}'.format(self.args['edge_density'], self.args['noise']))\n",
        "\n",
        "    def plot_train_accuracy(self):\n",
        "        plt.figure(1\n",
        "        plt.clf()\n",
        "        iters = range(len(self.accuracy_train))\n",
        "        plt.plot(iters, self.accuracy_train, 'b')\n",
        "        plt.xlabel('iterations')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title('Training Accuracy: p={}, p_e={}'.format(self.args['edge_density'], self.args['noise']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "icJ113zPOzgy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Trainer"
      ]
    },
    {
      "metadata": {
        "id": "Ik0sgcVVOzgy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "6fda8f2c-99bd-4b51-94ed-33b9641db9c9",
        "executionInfo": {
          "status": "error",
          "timestamp": 1525725313292,
          "user_tz": 240,
          "elapsed": 320,
          "user": {
            "displayName": "Luca Venturi",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "101973500851832681079"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def train(model, generator, logger, iterations=60000, batch_size=32, clip_grad_norm=40.0, print_freq=1000):\n",
        "    # model should be a siamese_gnn\n",
        "    # generator is the data_generator\n",
        "    labels = Variable(torch.arange(0, generator.N).unsqueeze(0).expand(batch_size,generator.N)).type(dtype_l)\n",
        "    # labels: [1,...,N] -> [[1,...N]] -> [[1,...N],...[1,...N]] of shape [batch_size,N]\n",
        "    # the labels are these since the embedding the GNN should reproduce are identities\n",
        "    optimizer = get_optimizer(model)\n",
        "    for iter_count in range(iterations):\n",
        "        input = generator.sample_batch(batch_size)\n",
        "        pred = model(*input)\n",
        "        loss = compute_loss(pred, labels)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm(model.parameters(), clip_grad_norm)\n",
        "        optimizer.step()\n",
        "        if iter_count % print_freq == 0:\n",
        "            print('Iter: {}, Loss: {:.4}'.format(iter_count,loss.data[0]))\n",
        "    print('Optimization finished.')\n",
        "    \n",
        "# Test\n",
        "\n",
        "args = {'edge density' : 0.2, 'noise' : 0.03}\n",
        "logger = make_logger()\n",
        "logger.args = args\n",
        "generator = dataGenerator()\n",
        "generator.edge_density = args['edge density']\n",
        "generator.noise = args['noise']\n",
        "generator.NUM_SAMPLES_train = 1000\n",
        "generator.N = 50\n",
        "J = 5\n",
        "generator.J = J-2\n",
        "generator.create_train_dataset()\n",
        "print('Dataset created')\n",
        "num_features = 10\n",
        "num_layers = 5\n",
        "siamese_gnn = Siamese_GNN(num_features, num_layers, J).type(dtype)\n",
        "train(siamese_gnn, generator, iterations=2000, batch_size=32, print_freq=100)\n",
        "\n",
        "# Test: OK"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-7e61280be15d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'edge density'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'noise'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m0.03\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'make_logger' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "SC1YsbMMOzg0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Main\n"
      ]
    },
    {
      "metadata": {
        "id": "H9-leymjOzg2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
